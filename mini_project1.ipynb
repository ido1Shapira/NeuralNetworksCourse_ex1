{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini-Project Number 1.  What Breast cancer will recur? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import all the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('wpbc.data', names= range(1,36), index_col= False, na_values=\"?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The describe of the data:\n",
    "\n",
    "1. Number of instances: 198\n",
    "\n",
    "2. Number of attributes: 34 (ID, outcome, 32 real-valued input features)\n",
    "\n",
    "3. Attribute information <br>\n",
    "    1) ID number <br>\n",
    "    2) Outcome (R = recur, N = nonrecur) <br>\n",
    "    3) Time (recurrence time if field 2 = R, disease-free time if field 2 = N) <br>\n",
    "    4-33) Ten real-valued features are computed for each cell nucleus: <br>\n",
    "    \n",
    "        a) radius (mean of distances from center to points on the perimeter)\n",
    "        b) texture (standard deviation of gray-scale values)\n",
    "        c) perimeter\n",
    "        d) area\n",
    "        e) smoothness (local variation in radius lengths)\n",
    "        f) compactness (perimeter^2 / area - 1.0)\n",
    "        g) concavity (severity of concave portions of the contour)\n",
    "        h) concave points (number of concave portions of the contour)\n",
    "        i) symmetry \n",
    "        j) fractal dimension (\"coastline approximation\" - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the first fields in the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119513</td>\n",
       "      <td>N</td>\n",
       "      <td>31</td>\n",
       "      <td>18.02</td>\n",
       "      <td>27.60</td>\n",
       "      <td>117.50</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>0.09489</td>\n",
       "      <td>0.1036</td>\n",
       "      <td>0.1086</td>\n",
       "      <td>...</td>\n",
       "      <td>139.70</td>\n",
       "      <td>1436.0</td>\n",
       "      <td>0.1195</td>\n",
       "      <td>0.1926</td>\n",
       "      <td>0.3140</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>0.2677</td>\n",
       "      <td>0.08113</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8423</td>\n",
       "      <td>N</td>\n",
       "      <td>61</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.2776</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>...</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>842517</td>\n",
       "      <td>N</td>\n",
       "      <td>116</td>\n",
       "      <td>21.37</td>\n",
       "      <td>17.44</td>\n",
       "      <td>137.50</td>\n",
       "      <td>1373.0</td>\n",
       "      <td>0.08836</td>\n",
       "      <td>0.1189</td>\n",
       "      <td>0.1255</td>\n",
       "      <td>...</td>\n",
       "      <td>159.10</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>0.1188</td>\n",
       "      <td>0.3449</td>\n",
       "      <td>0.3414</td>\n",
       "      <td>0.2032</td>\n",
       "      <td>0.4334</td>\n",
       "      <td>0.09067</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>843483</td>\n",
       "      <td>N</td>\n",
       "      <td>123</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.2839</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>...</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>843584</td>\n",
       "      <td>R</td>\n",
       "      <td>27</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>...</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>843786</td>\n",
       "      <td>R</td>\n",
       "      <td>77</td>\n",
       "      <td>12.75</td>\n",
       "      <td>15.29</td>\n",
       "      <td>84.60</td>\n",
       "      <td>502.7</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.1569</td>\n",
       "      <td>0.1664</td>\n",
       "      <td>...</td>\n",
       "      <td>107.30</td>\n",
       "      <td>733.2</td>\n",
       "      <td>0.1706</td>\n",
       "      <td>0.4196</td>\n",
       "      <td>0.5999</td>\n",
       "      <td>0.1709</td>\n",
       "      <td>0.3485</td>\n",
       "      <td>0.11790</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>844359</td>\n",
       "      <td>N</td>\n",
       "      <td>60</td>\n",
       "      <td>18.98</td>\n",
       "      <td>19.61</td>\n",
       "      <td>124.40</td>\n",
       "      <td>1112.0</td>\n",
       "      <td>0.09087</td>\n",
       "      <td>0.1237</td>\n",
       "      <td>0.1213</td>\n",
       "      <td>...</td>\n",
       "      <td>152.60</td>\n",
       "      <td>1593.0</td>\n",
       "      <td>0.1144</td>\n",
       "      <td>0.3371</td>\n",
       "      <td>0.2990</td>\n",
       "      <td>0.1922</td>\n",
       "      <td>0.2726</td>\n",
       "      <td>0.09581</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       1  2    3      4      5       6       7        8       9       10  ...  \\\n",
       "0  119513  N   31  18.02  27.60  117.50  1013.0  0.09489  0.1036  0.1086  ...   \n",
       "1    8423  N   61  17.99  10.38  122.80  1001.0  0.11840  0.2776  0.3001  ...   \n",
       "2  842517  N  116  21.37  17.44  137.50  1373.0  0.08836  0.1189  0.1255  ...   \n",
       "3  843483  N  123  11.42  20.38   77.58   386.1  0.14250  0.2839  0.2414  ...   \n",
       "4  843584  R   27  20.29  14.34  135.10  1297.0  0.10030  0.1328  0.1980  ...   \n",
       "5  843786  R   77  12.75  15.29   84.60   502.7  0.11890  0.1569  0.1664  ...   \n",
       "6  844359  N   60  18.98  19.61  124.40  1112.0  0.09087  0.1237  0.1213  ...   \n",
       "\n",
       "       26      27      28      29      30      31      32       33   34   35  \n",
       "0  139.70  1436.0  0.1195  0.1926  0.3140  0.1170  0.2677  0.08113  5.0  5.0  \n",
       "1  184.60  2019.0  0.1622  0.6656  0.7119  0.2654  0.4601  0.11890  3.0  2.0  \n",
       "2  159.10  1949.0  0.1188  0.3449  0.3414  0.2032  0.4334  0.09067  2.5  0.0  \n",
       "3   98.87   567.7  0.2098  0.8663  0.6869  0.2575  0.6638  0.17300  2.0  0.0  \n",
       "4  152.20  1575.0  0.1374  0.2050  0.4000  0.1625  0.2364  0.07678  3.5  0.0  \n",
       "5  107.30   733.2  0.1706  0.4196  0.5999  0.1709  0.3485  0.11790  2.5  0.0  \n",
       "6  152.60  1593.0  0.1144  0.3371  0.2990  0.1922  0.2726  0.09581  1.5  NaN  \n",
       "\n",
       "[7 rows x 35 columns]"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### searching for null data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "5     0\n",
       "6     0\n",
       "7     0\n",
       "8     0\n",
       "9     0\n",
       "10    0\n",
       "11    0\n",
       "12    0\n",
       "13    0\n",
       "14    0\n",
       "15    0\n",
       "16    0\n",
       "17    0\n",
       "18    0\n",
       "19    0\n",
       "20    0\n",
       "21    0\n",
       "22    0\n",
       "23    0\n",
       "24    0\n",
       "25    0\n",
       "26    0\n",
       "27    0\n",
       "28    0\n",
       "29    0\n",
       "30    0\n",
       "31    0\n",
       "32    0\n",
       "33    0\n",
       "34    0\n",
       "35    4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add: explain what to delete and why we dcieded to delete like that??????????????????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True, axis=0, how=\"any\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label encoding of the target:\n",
    "R = 1 = recurrent \n",
    "\n",
    "N = -1 = nonrecurrent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[2].replace({'N':-1,'R':1},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leave out the first column (participant’s ID) and the third column (the recurrence time) from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>...</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>18.02</td>\n",
       "      <td>27.60</td>\n",
       "      <td>117.50</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>0.09489</td>\n",
       "      <td>0.10360</td>\n",
       "      <td>0.10860</td>\n",
       "      <td>0.07055</td>\n",
       "      <td>0.1865</td>\n",
       "      <td>...</td>\n",
       "      <td>139.70</td>\n",
       "      <td>1436.0</td>\n",
       "      <td>0.11950</td>\n",
       "      <td>0.1926</td>\n",
       "      <td>0.3140</td>\n",
       "      <td>0.11700</td>\n",
       "      <td>0.2677</td>\n",
       "      <td>0.08113</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.26540</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>21.37</td>\n",
       "      <td>17.44</td>\n",
       "      <td>137.50</td>\n",
       "      <td>1373.0</td>\n",
       "      <td>0.08836</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.12550</td>\n",
       "      <td>0.08180</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>...</td>\n",
       "      <td>159.10</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>0.11880</td>\n",
       "      <td>0.3449</td>\n",
       "      <td>0.3414</td>\n",
       "      <td>0.20320</td>\n",
       "      <td>0.4334</td>\n",
       "      <td>0.09067</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.25750</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.16250</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>-1</td>\n",
       "      <td>14.72</td>\n",
       "      <td>25.26</td>\n",
       "      <td>99.28</td>\n",
       "      <td>657.5</td>\n",
       "      <td>0.11740</td>\n",
       "      <td>0.21120</td>\n",
       "      <td>0.17290</td>\n",
       "      <td>0.09465</td>\n",
       "      <td>0.2079</td>\n",
       "      <td>...</td>\n",
       "      <td>111.60</td>\n",
       "      <td>814.8</td>\n",
       "      <td>0.14640</td>\n",
       "      <td>0.5352</td>\n",
       "      <td>0.5655</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.3778</td>\n",
       "      <td>0.11320</td>\n",
       "      <td>1.7</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>-1</td>\n",
       "      <td>22.52</td>\n",
       "      <td>21.92</td>\n",
       "      <td>146.90</td>\n",
       "      <td>1597.0</td>\n",
       "      <td>0.07592</td>\n",
       "      <td>0.09162</td>\n",
       "      <td>0.06862</td>\n",
       "      <td>0.06367</td>\n",
       "      <td>0.1728</td>\n",
       "      <td>...</td>\n",
       "      <td>162.10</td>\n",
       "      <td>1902.0</td>\n",
       "      <td>0.08191</td>\n",
       "      <td>0.1319</td>\n",
       "      <td>0.1056</td>\n",
       "      <td>0.09378</td>\n",
       "      <td>0.2061</td>\n",
       "      <td>0.05788</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>-1</td>\n",
       "      <td>15.44</td>\n",
       "      <td>31.18</td>\n",
       "      <td>101.00</td>\n",
       "      <td>740.4</td>\n",
       "      <td>0.09399</td>\n",
       "      <td>0.10620</td>\n",
       "      <td>0.13750</td>\n",
       "      <td>0.06500</td>\n",
       "      <td>0.1735</td>\n",
       "      <td>...</td>\n",
       "      <td>112.60</td>\n",
       "      <td>929.0</td>\n",
       "      <td>0.12720</td>\n",
       "      <td>0.2362</td>\n",
       "      <td>0.2975</td>\n",
       "      <td>0.12860</td>\n",
       "      <td>0.2914</td>\n",
       "      <td>0.08024</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>-1</td>\n",
       "      <td>17.17</td>\n",
       "      <td>29.19</td>\n",
       "      <td>110.00</td>\n",
       "      <td>915.3</td>\n",
       "      <td>0.08952</td>\n",
       "      <td>0.06655</td>\n",
       "      <td>0.06583</td>\n",
       "      <td>0.05068</td>\n",
       "      <td>0.1793</td>\n",
       "      <td>...</td>\n",
       "      <td>132.50</td>\n",
       "      <td>1295.0</td>\n",
       "      <td>0.12610</td>\n",
       "      <td>0.1572</td>\n",
       "      <td>0.2141</td>\n",
       "      <td>0.09520</td>\n",
       "      <td>0.3362</td>\n",
       "      <td>0.06033</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>-1</td>\n",
       "      <td>16.70</td>\n",
       "      <td>28.13</td>\n",
       "      <td>110.30</td>\n",
       "      <td>885.4</td>\n",
       "      <td>0.08896</td>\n",
       "      <td>0.11310</td>\n",
       "      <td>0.10120</td>\n",
       "      <td>0.04989</td>\n",
       "      <td>0.1890</td>\n",
       "      <td>...</td>\n",
       "      <td>128.80</td>\n",
       "      <td>1213.0</td>\n",
       "      <td>0.13300</td>\n",
       "      <td>0.2808</td>\n",
       "      <td>0.3455</td>\n",
       "      <td>0.13170</td>\n",
       "      <td>0.3035</td>\n",
       "      <td>0.08036</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>194 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     2      4      5       6       7        8        9        10       11  \\\n",
       "0    -1  18.02  27.60  117.50  1013.0  0.09489  0.10360  0.10860  0.07055   \n",
       "1    -1  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.30010  0.14710   \n",
       "2    -1  21.37  17.44  137.50  1373.0  0.08836  0.11890  0.12550  0.08180   \n",
       "3    -1  11.42  20.38   77.58   386.1  0.14250  0.28390  0.24140  0.10520   \n",
       "4     1  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.19800  0.10430   \n",
       "..   ..    ...    ...     ...     ...      ...      ...      ...      ...   \n",
       "192  -1  14.72  25.26   99.28   657.5  0.11740  0.21120  0.17290  0.09465   \n",
       "193  -1  22.52  21.92  146.90  1597.0  0.07592  0.09162  0.06862  0.06367   \n",
       "194  -1  15.44  31.18  101.00   740.4  0.09399  0.10620  0.13750  0.06500   \n",
       "195  -1  17.17  29.19  110.00   915.3  0.08952  0.06655  0.06583  0.05068   \n",
       "197  -1  16.70  28.13  110.30   885.4  0.08896  0.11310  0.10120  0.04989   \n",
       "\n",
       "         12  ...      26      27       28      29      30       31      32  \\\n",
       "0    0.1865  ...  139.70  1436.0  0.11950  0.1926  0.3140  0.11700  0.2677   \n",
       "1    0.2419  ...  184.60  2019.0  0.16220  0.6656  0.7119  0.26540  0.4601   \n",
       "2    0.2333  ...  159.10  1949.0  0.11880  0.3449  0.3414  0.20320  0.4334   \n",
       "3    0.2597  ...   98.87   567.7  0.20980  0.8663  0.6869  0.25750  0.6638   \n",
       "4    0.1809  ...  152.20  1575.0  0.13740  0.2050  0.4000  0.16250  0.2364   \n",
       "..      ...  ...     ...     ...      ...     ...     ...      ...     ...   \n",
       "192  0.2079  ...  111.60   814.8  0.14640  0.5352  0.5655  0.19740  0.3778   \n",
       "193  0.1728  ...  162.10  1902.0  0.08191  0.1319  0.1056  0.09378  0.2061   \n",
       "194  0.1735  ...  112.60   929.0  0.12720  0.2362  0.2975  0.12860  0.2914   \n",
       "195  0.1793  ...  132.50  1295.0  0.12610  0.1572  0.2141  0.09520  0.3362   \n",
       "197  0.1890  ...  128.80  1213.0  0.13300  0.2808  0.3455  0.13170  0.3035   \n",
       "\n",
       "          33   34    35  \n",
       "0    0.08113  5.0   5.0  \n",
       "1    0.11890  3.0   2.0  \n",
       "2    0.09067  2.5   0.0  \n",
       "3    0.17300  2.0   0.0  \n",
       "4    0.07678  3.5   0.0  \n",
       "..       ...  ...   ...  \n",
       "192  0.11320  1.7  21.0  \n",
       "193  0.05788  6.0   2.0  \n",
       "194  0.08024  1.5   0.0  \n",
       "195  0.06033  3.7   0.0  \n",
       "197  0.08036  3.5   0.0  \n",
       "\n",
       "[194 rows x 33 columns]"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop([1, 3], axis = 1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(25,15))\n",
    "# sns.heatmap(data.corr(),annot=True,cmap='RdYlGn')\n",
    "# plt.title('Correlation Between All Features', size=20)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cm_analysis(y_true, y_pred, labels, figsize=(7,6)):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
    "    cm_perc = cm / cm_sum.astype(float) * 100\n",
    "    annot = np.empty_like(cm).astype(str)\n",
    "    nrows, ncols = cm.shape\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            c = cm[i, j]\n",
    "            p = cm_perc[i, j]\n",
    "            if i == j:\n",
    "                s = cm_sum[i]\n",
    "                annot[i, j] = '%.1f%%\\n%d/%d' % (p, c, s)\n",
    "            elif c == 0:\n",
    "                annot[i, j] = '0'\n",
    "            else:\n",
    "                annot[i, j] = '%.1f%%\\n%d' % (p, c)\n",
    "    cm = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "    cm.index.name = 'Actual'\n",
    "    cm.columns.name = 'Predicted'\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    sns.heatmap(cm, annot=annot, fmt='', ax=ax, cmap='Blues')\n",
    "    #plt.savefig(filename)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features Scaling & Train-Test Split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training dataset</th>\n",
       "      <th>Test dataset</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Recurrent</th>\n",
       "      <td>28</td>\n",
       "      <td>18</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nonrecurrent</th>\n",
       "      <td>101</td>\n",
       "      <td>47</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Training dataset  Test dataset  Total\n",
       "Recurrent                   28            18     46\n",
       "Nonrecurrent               101            47    148"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X = scaler.fit_transform(data.iloc[:, 1:].values)  \n",
    "y = data.iloc[:, 0].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = random_state )\n",
    "\n",
    "freqs = pd.DataFrame({\"Training dataset\": [(y_train == 1).sum(),(y_train == -1).sum()],\n",
    "                      \"Test dataset\": [(y_test == 1).sum(),(y_test == -1).sum()],\n",
    "                      \"Total\": [(y_train == 1).sum()+(y_test == 1).sum(),(y_train == -1).sum()+(y_test == -1).sum()]},\n",
    "                     index=[\"Recurrent\", \"Nonrecurrent\"])\n",
    "freqs[[\"Training dataset\", \"Test dataset\", \"Total\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:\n",
      " {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 50, 100), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(max_iter=100)\n",
    "\n",
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(32,18,8), (40, 30, 40), (100,50,100),(40,32,)],\n",
    "    'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "    'solver': ['lbfgs','sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant', 'invscaling','adaptive'],\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(mlp, parameter_space, n_jobs=-1, cv=3)\n",
    "clf.fit(X_train, y_train)\n",
    "# Best paramete set\n",
    "print('Best parameters found:\\n', clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(40, 32), random_state=1)"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='adam', hidden_layer_sizes=(40, 32, ), random_state=1)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_analysis(y_test, y_predict, clf.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of BP (split):  0.7384615384615385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of BP (cross-validation):  0.7322916666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of BP (split): \",metrics.accuracy_score(y_test, y_predict))\n",
    "print(\"Accuracy of BP (cross-validation): \",cross_val_score(clf, X, y, cv=3, scoring='accuracy').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standart Deviation of BP (cross-validation):  0.049401751568350666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(\"Standart Deviation of BP (cross-validation): \",cross_val_score(clf, X, y, cv=3, scoring='accuracy').std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives (TP): 6\n",
      "True Negatives (TN): 42\n",
      "False Positives (FP): 5\n",
      "False Negarives (FN): 12\n",
      "Classification Error: 0.26153846153846155\n",
      "Sensitivity: 0.3333333333333333\n",
      "Specificity: 0.8936170212765957\n"
     ]
    }
   ],
   "source": [
    "confusion = metrics.confusion_matrix(y_test, y_predict)\n",
    "TP = confusion[1, 1]\n",
    "TN = confusion[0, 0]\n",
    "FP = confusion[0, 1]\n",
    "FN = confusion[1, 0]\n",
    "print('True Positives (TP):',TP)\n",
    "print('True Negatives (TN):',TN)\n",
    "print('False Positives (FP):',FP)\n",
    "print('False Negarives (FN):',FN)\n",
    "print('Classification Error:',(FP + FN) / float(TP + TN + FP + FN))\n",
    "print('Sensitivity:',TP / float(TP + FN))\n",
    "print('Specificity:',TN / float(TN + FP))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
